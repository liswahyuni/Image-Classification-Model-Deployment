# -*- coding: utf-8 -*-
"""Lis Wahyuni - Proyek Akhir.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RFpWlJHZrONkSG-4a0MqY5AMi7eLxFgQ
"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle

!cp /content/kaggle.json ~/.kaggle/

# Permission for the json to act
!chmod 600 ~/.kaggle/kaggle.json

# List all datasets in Kaggle
!kaggle datasets list

!kaggle datasets download -d viratkothari/animal10

!ls

!unzip animal10.zip

dir_images='./Animals-10'

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras import optimizers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization
from tensorflow.keras.constraints import max_norm
import datetime

os.listdir(dir_images)

classes = ['dog',
 'butterfly',
 'sheep',
 'horse',
 'spider',
 'elephant',
 'chicken',
 'cow',
 'cat',
 'squirrel']

for cls in classes:
    path = os.path.join(dir_images, cls)
    for im_path in os.listdir(path):
        img = cv2.imread(os.path.join(path, im_path))
        plt.imshow(img)
        break
    break

dir_butterfly = os.listdir('/content/Animals-10/butterfly')
dir_cat = os.listdir('/content/Animals-10/cat')
dir_chicken = os.listdir('/content/Animals-10/chicken')
dir_cow = os.listdir('/content/Animals-10/cow')
dir_dog = os.listdir('/content/Animals-10/dog')
dir_elephant = os.listdir('/content/Animals-10/elephant')
dir_horse = os.listdir('/content/Animals-10/horse')
dir_sheep = os.listdir('/content/Animals-10/sheep')
dir_spider = os.listdir('/content/Animals-10/spider')
dir_squirrel = os.listdir('/content/Animals-10/squirrel')

print('Total butterfly images:',len(dir_butterfly))
print('Total cat images:',len(dir_cat))
print('Total chicken images:',len(dir_chicken))
print('Total cow images:',len(dir_cow))
print('Total dog images:',len(dir_dog))
print('Total elephant images:',len(dir_elephant))
print('Total horse images:',len(dir_horse))
print('Total sheep images:',len(dir_sheep))
print('Total spider images:',len(dir_spider))
print('Total squirrel images:',len(dir_squirrel))

dataset = []
def create_dataset():
    for cls in classes:
        cls_number = classes.index(cls)
        path = os.path.join(dir_images, cls)
        for img in os.listdir(path):
            try:
                img = cv2.imread(os.path.join(path, img))
                resize_img = cv2.resize(img, (32,32))
                dataset.append([resize_img, cls_number])
            except Exception as e:
                pass

"""# Bagian Baru"""

create_dataset()

X = []
y = []
for pict, label in dataset:
    X.append(pict)
    y.append(label)

X = np.array(X).reshape(-1, 32, 32, 3)
y = np.array(y)

print(type(X), X.shape)
print(type(y), y.shape)

from keras.preprocessing.image import ImageDataGenerator
from keras.utils.data_utils import Sequence
from imblearn.over_sampling import RandomOverSampler
from imblearn.tensorflow import balanced_batch_generator

!mkdir data
!mv /content/Animals-10/chicken /content/data/chicken/
!mv /content/Animals-10/dog /content/data/dog/
!mv /content/Animals-10/spider /content/data/spider/

train_dir = os.path.join('/content/data')
train_datagen = ImageDataGenerator(rescale=1./255,
                                   zoom_range=0.2,
                                   shear_range=0.2,
                                   rotation_range=40,
                                  #  width_shift_range=0.2,
                                  #  height_shift_range=0.2,
                                   horizontal_flip=True,
                                   vertical_flip=True,
                                   fill_mode = 'nearest',
                                   validation_split=0.2) # set validation split

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    # batch_size=8,
    class_mode='categorical',
    subset='training') # set as training data
validation_generator = train_datagen.flow_from_directory(
    train_dir, # same directory as training data
    target_size=(150, 150),
    # batch_size=16,
    class_mode='categorical',
    subset='validation')

CNN_model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),  
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(128, activation='relu'),    
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

CNN_model.summary()

CNN_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

file_writer = tf.summary.create_file_writer('/path/to/logs')

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if((logs.get('accuracy')>0.92 and logs.get('val_accuracy')>0.92)):
      print("\nAkurasi dan Val Akurasi telah di atas 92%.")
      self.model.stop_training = True
callbacks_stop = myCallback()

result = CNN_model.fit(train_generator,
                       epochs = 100,
                       validation_data=(validation_generator),
                       callbacks=[tensorboard_callback, callbacks_stop],
                       batch_size=128,
                       verbose=2)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/fit

plt.plot(result.history['loss'], 'black', linewidth=2.0)
plt.plot(result.history['val_loss'], 'red', linewidth=2.0)
plt.legend(['Training Loss', 'Validation Loss'], fontsize=14, loc='best')
plt.title('Loss Curves', fontsize=12)
plt.ylabel('Loss', fontsize=10)
plt.xlabel('Epochs', fontsize=10)
plt.show()

plt.plot(result.history['accuracy'], 'blue', linewidth=2.0)
plt.plot(result.history['val_accuracy'], 'orange', linewidth=2.0)
plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=14, loc='best')
plt.title('Accuracy Curves', fontsize=12)
plt.ylabel('Accuracy', fontsize=10)
plt.xlabel('Epochs', fontsize=10)
plt.show()

saving_path = ("/content/mymodel/") #path penyimpanan model
tf.saved_model.save(CNN_model, saving_path)

# Konversi model.
converter = tf.lite.TFLiteConverter.from_keras_model(CNN_model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('CNN_model.tflite', 'wb') as f:
  f.write(tflite_model)